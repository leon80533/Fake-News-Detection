{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X0bLNMI22fdj"
      },
      "outputs": [],
      "source": [
        "# import torch\n",
        "# torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a34bBV1TMRnG",
        "outputId": "7cc14802-9163-43e0-dd1a-48475f7b0932"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "os.chdir('/content/drive/MyDrive/Fake_news')\n",
        "\n",
        "import os\n",
        "from google.colab import drive\n",
        "MOUNTPOINT = '/content/drive'\n",
        "DATADIR = os.path.join(MOUNTPOINT, 'MyDrive', 'Fake_news')\n",
        "drive.mount(MOUNTPOINT)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rCLe_vA-MSFv",
        "outputId": "fd936b1d-a6f6-4a57-ca58-6992df02db72"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.21.0-py3-none-any.whl (4.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.7 MB 14.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.8.1-py3-none-any.whl (101 kB)\n",
            "\u001b[K     |████████████████████████████████| 101 kB 11.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 57.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 75.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.12.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n",
            "Installing collected packages: pyyaml, tokenizers, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.8.1 pyyaml-6.0 tokenizers-0.12.1 transformers-4.21.0\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qyGmTQCFMTEm"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json, re\n",
        "from tqdm import tqdm_notebook\n",
        "from uuid import uuid4\n",
        "\n",
        "## Torch Modules\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import Dataset, DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1MI5mVmZMavy"
      },
      "outputs": [],
      "source": [
        "# Use GPU\n",
        "device = torch.device(\"cuda\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GZaRndpzMcPk"
      },
      "outputs": [],
      "source": [
        "from imblearn.pipeline import Pipeline, make_pipeline\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.naive_bayes import MultinomialNB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X3SSTvDFMdZj"
      },
      "outputs": [],
      "source": [
        "from imblearn.over_sampling import SMOTE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tVHhVruQyY1W"
      },
      "outputs": [],
      "source": [
        "from sklearn.utils import shuffle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qyAdPl6tMfD3"
      },
      "outputs": [],
      "source": [
        "df_train = pd.read_csv(\"Constraint_Train_p.csv\")\n",
        "df_test = pd.read_csv(\"Constraint_Test_p.csv\")\n",
        "df_val = pd.read_csv(\"Constraint_Val_p.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-FitlB0bMgLl"
      },
      "outputs": [],
      "source": [
        "df = pd.concat([df_train,df_val],axis=0,ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rVuVJFE4yeOC"
      },
      "outputs": [],
      "source": [
        "df = shuffle(df, random_state=0)\n",
        "sentences = df['text'] \n",
        "labels = df['label']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SqNYBmQvtw0M",
        "outputId": "5acee119-ceb0-42ba-c02d-17e3e523cf5f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 11.8 MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.96\n"
          ]
        }
      ],
      "source": [
        "!pip install sentencepiece"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EG2lnEgIMir_"
      },
      "outputs": [],
      "source": [
        "from transformers import (BertForSequenceClassification,BertTokenizer,\n",
        "                          RobertaForSequenceClassification,RobertaTokenizer,\n",
        "                         AdamW)\n",
        "from transformers import XLNetTokenizer, XLNetModel, XLNetForSequenceClassification\n",
        "import torch\n",
        "\n",
        "from transformers import (\n",
        "  AutoModel,\n",
        "   AutoConfig,\n",
        "   AutoTokenizer,\n",
        "   TFAutoModelForSequenceClassification,\n",
        "   AdamW,\n",
        "   glue_convert_examples_to_features,\n",
        "   BertConfig,\n",
        "   AutoModelForSequenceClassification\n",
        ")\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import json\n",
        "\n",
        "# BERT\n",
        "bert_model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n",
        "                                                                num_labels = 2, # The number of output labels--2 for binary classification.\n",
        "                                                                                # You can increase this for multi-class tasks.   \n",
        "                                                                output_attentions = False, # Whether the model returns attentions weights.\n",
        "                                                                output_hidden_states = False # Whether the model returns all hidden-states.\n",
        "                                                          )\n",
        "bert_tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "bert_model.cuda()\n",
        "                                                           \n",
        "\n",
        "# RoBERTa\n",
        "roberta_model = RobertaForSequenceClassification.from_pretrained(\"roberta-base\", # 12-layer, 768-hidden, 12-heads, 125M parameters RoBERTa using the BERT-base architecture\n",
        "                                                                    num_labels = 2, # The number of output labels--2 for binary classification.\n",
        "                                                                                    # You can increase this for multi-class tasks.   \n",
        "                                                                    output_attentions = False, # Whether the model returns attentions weights.\n",
        "                                                                    output_hidden_states = False # Whether the model returns all hidden-states.\n",
        "                                                                )\n",
        "roberta_tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
        "roberta_model.cuda()\n",
        "\n",
        "# XLNet\n",
        "xlnet_model = XLNetForSequenceClassification.from_pretrained('xlnet-base-cased', num_labels = 2, output_attentions = False, output_hidden_states = False)\n",
        "xlnet_tokenizer = XLNetTokenizer.from_pretrained(\"xlnet-base-cased\")\n",
        "\n",
        "xlnet_model.cuda()\n",
        "\n",
        "# CT-BERT\n",
        "# ctbert_model = AutoModel.from_pretrained(\"digitalepidemiologylab/covid-twitter-bert\", num_labels = 2, output_attentions = False, output_hidden_states = False)\n",
        "ctbert_tokenizer = AutoTokenizer.from_pretrained(\"digitalepidemiologylab/covid-twitter-bert\")\n",
        "\n",
        "config = BertConfig.from_pretrained(\"digitalepidemiologylab/covid-twitter-bert\", num_labels = 2, output_attentions = False, output_hidden_states = False)    # Download configuration from S3 and cache.\n",
        "ctbert_model = AutoModelForSequenceClassification.from_config(config) \n",
        "ctbert_model.cuda()\n",
        "\n",
        "# BT-BERT\n",
        "btbert_tokenizer = AutoTokenizer.from_pretrained(\"vinai/bertweet-base\")\n",
        "\n",
        "bt_config = BertConfig.from_pretrained(\"vinai/bertweet-base\", num_labels = 2, output_attentions = False, output_hidden_states = False)    # Download configuration from S3 and cache.\n",
        "btbert_model = AutoModelForSequenceClassification.from_config(bt_config) \n",
        "\n",
        "btbert_model.cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DvfjIGLEMy6B",
        "outputId": "4a801e92-1420-400a-e1e3-d47b2583271b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (368 > 128). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1094 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1126 > 512). Running this sequence through the model will result in indexing errors\n"
          ]
        }
      ],
      "source": [
        "max_len_bert = 0\n",
        "max_len_roberta = 0\n",
        "max_len_xlnet = 0\n",
        "max_len_ctbert = 0\n",
        "max_len_btbert = 0\n",
        "\n",
        "\n",
        "\n",
        "# For every sentence...\n",
        "for sent in sentences:\n",
        "\n",
        "    # Tokenize the text and add `[CLS]` and `[SEP]` tokens.\n",
        "    input_ids_bert = bert_tokenizer.encode(sent, add_special_tokens=True)\n",
        "    input_ids_roberta = roberta_tokenizer.encode(sent, add_special_tokens=True)\n",
        "    input_ids_xlnet = xlnet_tokenizer.encode(sent, add_special_tokens=True)\n",
        "    input_ids_ctbert = ctbert_tokenizer.encode(sent, add_special_tokens=True)\n",
        "    input_ids_btbert = btbert_tokenizer.encode(sent, add_special_tokens=True)\n",
        "\n",
        "\n",
        "    # Update the maximum sentence length.\n",
        "    max_len_bert = max(max_len_bert, len(input_ids_bert))\n",
        "    max_len_roberta = max(max_len_roberta, len(input_ids_roberta))\n",
        "    max_len_xlnet = max(max_len_xlnet, len(input_ids_xlnet))\n",
        "    max_len_ctbert = max(max_len_ctbert, len(input_ids_ctbert))\n",
        "    max_len_btbert = max(max_len_btbert, len(input_ids_btbert))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lq8GH7aaM4mE",
        "outputId": "1c37190e-74e1-4fc1-fd77-228b3154db1a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        }
      ],
      "source": [
        "bert_input_ids = []\n",
        "bert_attention_masks = []\n",
        "roberta_input_ids = []\n",
        "roberta_attention_masks = []\n",
        "xlnet_input_ids = []\n",
        "xlnet_attention_masks = []\n",
        "ctbert_input_ids = []\n",
        "ctbert_attention_masks = []\n",
        "btbert_input_ids = []\n",
        "btbert_attention_masks = []\n",
        "sentence_ids = []\n",
        "counter = 0\n",
        "\n",
        "# For every sentence...\n",
        "for sent in sentences:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    bert_encoded_dict = bert_tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 120,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    \n",
        "    roberta_encoded_dict = roberta_tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 120,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    xlnet_encoded_dict = xlnet_tokenizer.encode_plus(\n",
        "                    sent,                      # Sentence to encode.\n",
        "                    add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                    max_length = 120,           # Pad & truncate all sentences.\n",
        "                    pad_to_max_length = True,\n",
        "                    return_attention_mask = True,   # Construct attn. masks.\n",
        "                    return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                )\n",
        "    \n",
        "    ctbert_encoded_dict = ctbert_tokenizer.encode_plus(\n",
        "                    sent,                      # Sentence to encode.\n",
        "                    add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                    max_length = 120,           # Pad & truncate all sentences.\n",
        "                    pad_to_max_length = True,\n",
        "                    return_attention_mask = True,   # Construct attn. masks.\n",
        "                    return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                )\n",
        "    \n",
        "    btbert_encoded_dict = btbert_tokenizer.encode_plus(\n",
        "                sent,                      # Sentence to encode.\n",
        "                add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                max_length = 120,           # Pad & truncate all sentences.\n",
        "                pad_to_max_length = True,\n",
        "                return_attention_mask = True,   # Construct attn. masks.\n",
        "                return_tensors = 'pt',     # Return pytorch tensors.\n",
        "            )\n",
        "\n",
        "    # Add the encoded sentence to the list.    \n",
        "    bert_input_ids.append(bert_encoded_dict['input_ids'])\n",
        "    roberta_input_ids.append(roberta_encoded_dict['input_ids'])\n",
        "    xlnet_input_ids.append(xlnet_encoded_dict['input_ids'])\n",
        "    ctbert_input_ids.append(ctbert_encoded_dict['input_ids'])\n",
        "    btbert_input_ids.append(btbert_encoded_dict['input_ids'])\n",
        "\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    bert_attention_masks.append(bert_encoded_dict['attention_mask'])\n",
        "    roberta_attention_masks.append(roberta_encoded_dict['attention_mask'])\n",
        "    xlnet_attention_masks.append(xlnet_encoded_dict['attention_mask'])\n",
        "    ctbert_attention_masks.append(ctbert_encoded_dict['attention_mask'])\n",
        "    btbert_attention_masks.append(btbert_encoded_dict['attention_mask'])\n",
        "    \n",
        "    \n",
        "    # collecting sentence_ids\n",
        "    sentence_ids.append(counter)\n",
        "    counter  = counter + 1\n",
        "    \n",
        "# Convert the lists into tensors.\n",
        "bert_input_ids = torch.cat(bert_input_ids, dim=0)\n",
        "bert_attention_masks = torch.cat(bert_attention_masks, dim=0)\n",
        "\n",
        "roberta_input_ids = torch.cat(roberta_input_ids, dim=0)\n",
        "roberta_attention_masks = torch.cat(roberta_attention_masks, dim=0)\n",
        "\n",
        "xlnet_input_ids = torch.cat(xlnet_input_ids, dim=0)\n",
        "xlnet_attention_masks = torch.cat(xlnet_attention_masks, dim=0)\n",
        "\n",
        "ctbert_input_ids = torch.cat(ctbert_input_ids, dim=0)\n",
        "ctbert_attention_masks = torch.cat(ctbert_attention_masks, dim=0)\n",
        "\n",
        "\n",
        "btbert_input_ids = torch.cat(btbert_input_ids, dim=0)\n",
        "btbert_attention_masks = torch.cat(btbert_attention_masks, dim=0)\n",
        "\n",
        "labels = torch.tensor(labels)\n",
        "sentence_ids = torch.tensor(sentence_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D5Ys1oHGZxGZ"
      },
      "outputs": [],
      "source": [
        "def index_remover(tensordata):\n",
        "    input_ids = []\n",
        "    attention_masks = []\n",
        "    labels = []\n",
        "   \n",
        "    for a,b,c,d in tensordata:\n",
        "        input_ids.append(b.tolist())\n",
        "        attention_masks.append(c.tolist())\n",
        "        labels.append(d.tolist())\n",
        "        \n",
        "    input_ids = torch.tensor(input_ids)\n",
        "    attention_masks = torch.tensor(attention_masks)\n",
        "    labels = torch.tensor(labels)\n",
        "    \n",
        "    final_dataset =  TensorDataset(input_ids, attention_masks, labels)\n",
        "    return final_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o0t7yX3ZN0sO"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import TensorDataset, random_split\n",
        "# function to seed the script globally\n",
        "torch.manual_seed(0)\n",
        "\n",
        "# Combine the training inputs into a TensorDataset.\n",
        "bert_dataset = TensorDataset(sentence_ids, bert_input_ids, bert_attention_masks, labels)\n",
        "roberta_dataset = TensorDataset(roberta_input_ids, roberta_attention_masks, labels)\n",
        "xlnet_dataset = TensorDataset(xlnet_input_ids, xlnet_attention_masks, labels)\n",
        "ctbert_dataset = TensorDataset(sentence_ids, ctbert_input_ids, ctbert_attention_masks, labels)\n",
        "btbert_dataset = TensorDataset(sentence_ids, btbert_input_ids, btbert_attention_masks, labels)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "31sjFGiQN8CX"
      },
      "outputs": [],
      "source": [
        "train_size = int(0.8 * len(roberta_dataset))\n",
        "val_size = len(roberta_dataset) - train_size\n",
        "\n",
        "# Divide the dataset by randomly selecting samples.\n",
        "# bert_train_dataset, bert_val_dataset = random_split(bert_dataset, [train_size, val_size])\n",
        "# roberta_train_dataset, roberta_val_dataset = random_split(roberta_dataset, [train_size, val_size])\n",
        "# xlnet_train_dataset, xlnet_val_dataset = random_split(xlnet_dataset, [train_size, val_size])\n",
        "\n",
        "bert_train_dataset = torch.utils.data.Subset(bert_dataset, range(train_size))\n",
        "bert_val_dataset = torch.utils.data.Subset(bert_dataset, range(train_size, train_size + val_size))\n",
        "roberta_train_dataset = torch.utils.data.Subset(roberta_dataset, range(train_size))\n",
        "roberta_val_dataset = torch.utils.data.Subset(roberta_dataset, range(train_size, train_size + val_size))\n",
        "xlnet_train_dataset = torch.utils.data.Subset(xlnet_dataset, range(train_size))\n",
        "xlnet_val_dataset = torch.utils.data.Subset(xlnet_dataset, range(train_size, train_size + val_size))\n",
        "ctbert_train_dataset = torch.utils.data.Subset(ctbert_dataset, range(train_size))\n",
        "ctbert_val_dataset = torch.utils.data.Subset(ctbert_dataset, range(train_size, train_size + val_size))\n",
        "btbert_train_dataset = torch.utils.data.Subset(btbert_dataset, range(train_size))\n",
        "btbert_val_dataset = torch.utils.data.Subset(btbert_dataset, range(train_size, train_size + val_size))\n",
        "\n",
        "bert_train_dataset = index_remover(bert_train_dataset)\n",
        "bert_val_dataset = index_remover(bert_val_dataset)\n",
        "ctbert_train_dataset = index_remover(ctbert_train_dataset)\n",
        "ctbert_val_dataset = index_remover(ctbert_val_dataset)\n",
        "btbert_train_dataset = index_remover(btbert_train_dataset)\n",
        "btbert_val_dataset = index_remover(btbert_val_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kZd7nXRvOoY2"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# The DataLoader needs to know our batch size for training, so we specify it \n",
        "# here. For fine-tuning BERT on a specific task, the authors recommend a batch \n",
        "# size of 16 or 32.\n",
        "batch_size = 32\n",
        "\n",
        "# Create the DataLoaders for our training and validation sets.\n",
        "# We'll take training samples in random order. \n",
        "bert_train_dataloader = DataLoader(\n",
        "            bert_train_dataset,  # The training samples.\n",
        "            sampler = RandomSampler(bert_train_dataset), # Select batches randomly\n",
        "            batch_size = batch_size # Trains with this batch size.\n",
        "        )\n",
        "roberta_train_dataloader = DataLoader(\n",
        "            roberta_train_dataset,  # The training samples.\n",
        "            sampler = RandomSampler(roberta_train_dataset), # Select batches randomly\n",
        "            batch_size = batch_size # Trains with this batch size.\n",
        "        )\n",
        "\n",
        "xlnet_train_dataloader = DataLoader(\n",
        "            xlnet_train_dataset,  # The training samples.\n",
        "            sampler = RandomSampler(xlnet_train_dataset), # Select batches randomly\n",
        "            batch_size = batch_size # Trains with this batch size.\n",
        "        )\n",
        "\n",
        "ctbert_train_dataloader = DataLoader(\n",
        "            ctbert_train_dataset,  # The training samples.\n",
        "            sampler = RandomSampler(ctbert_train_dataset), # Select batches randomly\n",
        "            batch_size = batch_size # Trains with this batch size.\n",
        "        )\n",
        "\n",
        "\n",
        "btbert_train_dataloader = DataLoader(\n",
        "            btbert_train_dataset,  # The training samples.\n",
        "            sampler = RandomSampler(btbert_train_dataset), # Select batches randomly\n",
        "            batch_size = batch_size # Trains with this batch size.\n",
        "        )\n",
        "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
        "bert_validation_dataloader = DataLoader(\n",
        "            bert_val_dataset, # The validation samples.\n",
        "            sampler = SequentialSampler(bert_val_dataset), # Pull out batches sequentially.\n",
        "            batch_size = batch_size # Evaluate with this batch size.\n",
        "        )\n",
        "\n",
        "roberta_validation_dataloader = DataLoader(\n",
        "            roberta_val_dataset, # The validation samples.\n",
        "            sampler = SequentialSampler(roberta_val_dataset), # Pull out batches sequentially.\n",
        "            batch_size = batch_size # Evaluate with this batch size.\n",
        "        )\n",
        "xlnet_validation_dataloader = DataLoader(\n",
        "            xlnet_val_dataset, # The validation samples.\n",
        "            sampler = SequentialSampler(xlnet_val_dataset), # Pull out batches sequentially.\n",
        "            batch_size = batch_size # Evaluate with this batch size.\n",
        "        )\n",
        "ctbert_validation_dataloader = DataLoader(\n",
        "            ctbert_val_dataset, # The validation samples.\n",
        "            sampler = SequentialSampler(ctbert_val_dataset), # Pull out batches sequentially.\n",
        "            batch_size = batch_size # Evaluate with this batch size.\n",
        "        )\n",
        "btbert_validation_dataloader = DataLoader(\n",
        "            btbert_val_dataset, # The validation samples.\n",
        "            sampler = SequentialSampler(btbert_val_dataset), # Pull out batches sequentially.\n",
        "            batch_size = batch_size # Evaluate with this batch size.\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A562WUvWOtA2",
        "outputId": "1d8abb23-a0bd-45b4-9727-980aca6ea58d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n"
          ]
        }
      ],
      "source": [
        "# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n",
        "# I believe the 'W' stands for 'Weight Decay fix\"\n",
        "bert_optimizer = AdamW(bert_model.parameters(),\n",
        "                  lr = 5e-5, # args.learning_rate - default is 5e-5\n",
        "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                )\n",
        "\n",
        "roberta_optimizer = AdamW(roberta_model.parameters(),\n",
        "                  lr = 5e-5, # args.learning_rate - default is 5e-5\n",
        "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                )\n",
        "xlnet_optimizer = AdamW(xlnet_model.parameters(),\n",
        "                  lr = 5e-5, # args.learning_rate - default is 5e-5\n",
        "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                )\n",
        "\n",
        "ctbert_optimizer = AdamW(ctbert_model.parameters(),\n",
        "                  lr = 5e-5, # args.learning_rate - default is 5e-5\n",
        "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                )\n",
        "btbert_optimizer = AdamW(btbert_model.parameters(),\n",
        "                  lr = 5e-5, # args.learning_rate - default is 5e-5\n",
        "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4yEIuZuWOv1C"
      },
      "outputs": [],
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# Number of training epochs. The BERT authors recommend between 2 and 4. \n",
        "# We chose to run for 2,I have already seen that the model starts overfitting beyound 2 epochs\n",
        "epochs = 30\n",
        "\n",
        "# Total number of training steps is [number of batches] x [number of epochs]. \n",
        "# (Note that this is not the same as the number of training samples).\n",
        "total_steps = len(bert_train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "bert_scheduler = get_linear_schedule_with_warmup(bert_optimizer, \n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)\n",
        "\n",
        "roberta_scheduler = get_linear_schedule_with_warmup(roberta_optimizer, \n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)\n",
        "xlnet_scheduler = get_linear_schedule_with_warmup(xlnet_optimizer, \n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)\n",
        "\n",
        "ctbert_scheduler = get_linear_schedule_with_warmup(ctbert_optimizer, \n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)\n",
        "btbert_scheduler = get_linear_schedule_with_warmup(btbert_optimizer, \n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2rV1KyRAO14b"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xN3gBBgaO3Gk"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ix9W6x9LyD9o",
        "outputId": "dbbc7c74-6049-455e-fb81-ae387040db83"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    214.    Elapsed: 0:00:15.\n",
            "  Batch    80  of    214.    Elapsed: 0:00:29.\n",
            "  Batch   120  of    214.    Elapsed: 0:00:44.\n",
            "  Batch   160  of    214.    Elapsed: 0:00:58.\n",
            "  Batch   200  of    214.    Elapsed: 0:01:13.\n",
            "\n",
            "  Average training loss: 0.01\n",
            "  Training epcoh took: 0:01:18\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.95\n",
            "  Validation Loss: 0.31\n",
            "  Validation took: 0:00:06\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    214.    Elapsed: 0:00:15.\n",
            "  Batch    80  of    214.    Elapsed: 0:00:29.\n",
            "  Batch   120  of    214.    Elapsed: 0:00:44.\n",
            "  Batch   160  of    214.    Elapsed: 0:00:58.\n",
            "  Batch   200  of    214.    Elapsed: 0:01:13.\n",
            "\n",
            "  Average training loss: 0.01\n",
            "  Training epcoh took: 0:01:18\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.95\n",
            "  Validation Loss: 0.31\n",
            "  Validation took: 0:00:06\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    214.    Elapsed: 0:00:15.\n",
            "  Batch    80  of    214.    Elapsed: 0:00:29.\n",
            "  Batch   120  of    214.    Elapsed: 0:00:44.\n",
            "  Batch   160  of    214.    Elapsed: 0:00:58.\n",
            "  Batch   200  of    214.    Elapsed: 0:01:13.\n",
            "\n",
            "  Average training loss: 0.01\n",
            "  Training epcoh took: 0:01:18\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.95\n",
            "  Validation Loss: 0.31\n",
            "  Validation took: 0:00:06\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    214.    Elapsed: 0:00:15.\n",
            "  Batch    80  of    214.    Elapsed: 0:00:29.\n",
            "  Batch   120  of    214.    Elapsed: 0:00:44.\n",
            "  Batch   160  of    214.    Elapsed: 0:00:58.\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "seed_val = 100\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "btbert_training_stats = []\n",
        "\n",
        "# Measure the total training time for the whole run.\n",
        "total_t0 = time.time()\n",
        "\n",
        "for epoch_i in range(0, epochs):\n",
        "    btbert_outputs_prob = []\n",
        "  \n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_train_loss = 0\n",
        "    btbert_model.train()\n",
        "\n",
        "    for step, batch in enumerate(btbert_train_dataloader):\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "      \n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(btbert_train_dataloader), elapsed))\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "        btbert_model.zero_grad()\n",
        "\n",
        "        outputs = btbert_model(b_input_ids, \n",
        "                             attention_mask=b_input_mask, \n",
        "                             labels=b_labels)\n",
        "\n",
        "        # Accumulate the training loss over all of the batches so that we can\n",
        "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "        # single value; the `.item()` function just returns the Python value \n",
        "        # from the tensor.\n",
        "\n",
        "        total_train_loss += outputs.loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        outputs.loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(btbert_model.parameters(), 1.0)\n",
        "\n",
        "        btbert_optimizer.step()\n",
        "        btbert_scheduler.step()\n",
        "\n",
        "    avg_train_loss = total_train_loss / len(btbert_train_dataloader)            \n",
        "    \n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    btbert_model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    total_eval_accuracy = 0\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in btbert_validation_dataloader:\n",
        "\n",
        "        \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "        with torch.no_grad():\n",
        "       \n",
        "\n",
        "            # Forward pass, calculate logit predictions.\n",
        "            # token_type_ids is the same as the \"segment ids\", which \n",
        "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "            # Get the \"logits\" output by the roberta_model. The \"logits\" are the output\n",
        "            # values prior to applying an activation function like the softmax.\n",
        "            outputs = btbert_model(b_input_ids, \n",
        "#                                    token_type_ids=None, \n",
        "                                   attention_mask=b_input_mask,\n",
        "                                   labels=b_labels)\n",
        "            \n",
        "        # Accumulate the validation loss.\n",
        "        total_eval_loss += outputs.loss.item()\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        outputs.logits = outputs.logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        # Calculate the accuracy for this batch of test sentences, and\n",
        "        # accumulate it over all batches.\n",
        "        for logit in outputs.logits:\n",
        "          btbert_outputs_prob.append(logit.tolist())\n",
        "\n",
        "        total_eval_accuracy += flat_accuracy(outputs.logits, label_ids)\n",
        "        \n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    avg_val_accuracy = total_eval_accuracy / len(btbert_validation_dataloader)\n",
        "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_val_loss = total_eval_loss / len(btbert_validation_dataloader)\n",
        "    \n",
        "    # Measure how long the validation run took.\n",
        "    validation_time = format_time(time.time() - t0)\n",
        "    \n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "    # Record all statistics from this epoch.\n",
        "    btbert_training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Valid. Accur.': avg_val_accuracy,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "X1PaQL-Y9jp4"
      },
      "outputs": [],
      "source": [
        "df_bt_stats = pd.DataFrame(data=btbert_training_stats)\n",
        "df_bt_stats = df_bt_stats.set_index('epoch')\n",
        "df_bt_stats.to_csv('df_bt_stats_4.csv') "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yAfXo71boyY7"
      },
      "outputs": [],
      "source": [
        "df_bt_stats = pd.DataFrame(data=btbert_training_stats)\n",
        "df_bt_stats = df_bt_stats.set_index('epoch')\n",
        "df_bt_stats.to_csv('df_bt_stats.csv')  \n",
        "np_btbert_outputs_prob = np.array([np.array(xi) for xi in btbert_outputs_prob])\n",
        "np.save('btbert_outputs_prob.npy',np_btbert_outputs_prob)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KJ3Dwu7N9wIL"
      },
      "outputs": [],
      "source": [
        "df_bt_stats.to_csv('df_bt_stats.csv')  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "psC47lrs-Nmc"
      },
      "outputs": [],
      "source": [
        "np_btbert_outputs_prob = np.array([np.array(xi) for xi in btbert_outputs_prob])\n",
        "np.save('btbert_outputs_prob.npy',np_btbert_outputs_prob)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QhURC0SA-Ud8",
        "outputId": "ef9e571b-5bf8-4293-8a6a-e04beb3144c3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[-2.87617421,  2.11003757],\n",
              "       [-3.77582765,  3.07525754],\n",
              "       [-3.50905228,  2.76657724],\n",
              "       ...,\n",
              "       [-3.73377061,  3.02959466],\n",
              "       [ 3.89040422, -3.43641305],\n",
              "       [ 3.89586043, -3.44005728]])"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.save('btbert_outputs_prob.npy',np_btbert_outputs_prob)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZwO9kd67xQuM",
        "outputId": "f4e2fc89-4085-4a74-c5f1-5e3f850ca479"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 5 ========\n",
            "Training...\n",
            "  Batch    40  of    214.    Elapsed: 0:00:48.\n",
            "  Batch    80  of    214.    Elapsed: 0:01:35.\n",
            "  Batch   120  of    214.    Elapsed: 0:02:21.\n",
            "  Batch   160  of    214.    Elapsed: 0:03:07.\n",
            "  Batch   200  of    214.    Elapsed: 0:03:53.\n",
            "\n",
            "  Average training loss: 0.73\n",
            "  Training epcoh took: 0:04:09\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.52\n",
            "  Validation Loss: 0.69\n",
            "  Validation took: 0:00:20\n",
            "\n",
            "======== Epoch 2 / 5 ========\n",
            "Training...\n",
            "  Batch    40  of    214.    Elapsed: 0:00:46.\n",
            "  Batch    80  of    214.    Elapsed: 0:01:32.\n",
            "  Batch   120  of    214.    Elapsed: 0:02:18.\n",
            "  Batch   160  of    214.    Elapsed: 0:03:05.\n",
            "  Batch   200  of    214.    Elapsed: 0:03:51.\n",
            "\n",
            "  Average training loss: 0.71\n",
            "  Training epcoh took: 0:04:07\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.48\n",
            "  Validation Loss: 0.70\n",
            "  Validation took: 0:00:20\n",
            "\n",
            "======== Epoch 3 / 5 ========\n",
            "Training...\n",
            "  Batch    40  of    214.    Elapsed: 0:00:46.\n",
            "  Batch    80  of    214.    Elapsed: 0:01:32.\n",
            "  Batch   120  of    214.    Elapsed: 0:02:18.\n",
            "  Batch   160  of    214.    Elapsed: 0:03:05.\n",
            "  Batch   200  of    214.    Elapsed: 0:03:51.\n",
            "\n",
            "  Average training loss: 0.71\n",
            "  Training epcoh took: 0:04:07\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.52\n",
            "  Validation Loss: 0.69\n",
            "  Validation took: 0:00:20\n",
            "\n",
            "======== Epoch 4 / 5 ========\n",
            "Training...\n",
            "  Batch    40  of    214.    Elapsed: 0:00:46.\n",
            "  Batch    80  of    214.    Elapsed: 0:01:32.\n",
            "  Batch   120  of    214.    Elapsed: 0:02:18.\n",
            "  Batch   160  of    214.    Elapsed: 0:03:05.\n",
            "  Batch   200  of    214.    Elapsed: 0:03:51.\n",
            "\n",
            "  Average training loss: 0.70\n",
            "  Training epcoh took: 0:04:07\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.52\n",
            "  Validation Loss: 0.69\n",
            "  Validation took: 0:00:20\n",
            "\n",
            "======== Epoch 5 / 5 ========\n",
            "Training...\n",
            "  Batch    40  of    214.    Elapsed: 0:00:46.\n",
            "  Batch    80  of    214.    Elapsed: 0:01:32.\n",
            "  Batch   120  of    214.    Elapsed: 0:02:18.\n",
            "  Batch   160  of    214.    Elapsed: 0:03:05.\n",
            "  Batch   200  of    214.    Elapsed: 0:03:51.\n",
            "\n",
            "  Average training loss: 0.70\n",
            "  Training epcoh took: 0:04:07\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.52\n",
            "  Validation Loss: 0.70\n",
            "  Validation took: 0:00:20\n",
            "\n",
            "Training complete!\n",
            "Total training took 0:22:17 (h:mm:ss)\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "seed_val = 100\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "ctbert_training_stats = []\n",
        "\n",
        "# Measure the total training time for the whole run.\n",
        "total_t0 = time.time()\n",
        "\n",
        "for epoch_i in range(0, epochs):\n",
        "    ctbert_outputs_prob = []\n",
        "  \n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_train_loss = 0\n",
        "    ctbert_model.train()\n",
        "\n",
        "    for step, batch in enumerate(ctbert_train_dataloader):\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "      \n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(ctbert_train_dataloader), elapsed))\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "        ctbert_model.zero_grad()\n",
        "\n",
        "        outputs = ctbert_model(b_input_ids, \n",
        "                             attention_mask=b_input_mask, \n",
        "                             labels=b_labels)\n",
        "\n",
        "        # Accumulate the training loss over all of the batches so that we can\n",
        "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "        # single value; the `.item()` function just returns the Python value \n",
        "        # from the tensor.\n",
        "\n",
        "        total_train_loss += outputs.loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        outputs.loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(ctbert_model.parameters(), 1.0)\n",
        "\n",
        "        ctbert_optimizer.step()\n",
        "        ctbert_scheduler.step()\n",
        "\n",
        "    avg_train_loss = total_train_loss / len(ctbert_train_dataloader)            \n",
        "    \n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    ctbert_model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    total_eval_accuracy = 0\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in ctbert_validation_dataloader:\n",
        "\n",
        "        \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "        with torch.no_grad():\n",
        "       \n",
        "\n",
        "            # Forward pass, calculate logit predictions.\n",
        "            # token_type_ids is the same as the \"segment ids\", which \n",
        "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "            # Get the \"logits\" output by the roberta_model. The \"logits\" are the output\n",
        "            # values prior to applying an activation function like the softmax.\n",
        "            outputs = ctbert_model(b_input_ids, \n",
        "#                                    token_type_ids=None, \n",
        "                                   attention_mask=b_input_mask,\n",
        "                                   labels=b_labels)\n",
        "            \n",
        "        # Accumulate the validation loss.\n",
        "        total_eval_loss += outputs.loss.item()\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        outputs.logits = outputs.logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        # Calculate the accuracy for this batch of test sentences, and\n",
        "        # accumulate it over all batches.\n",
        "        for logit in outputs.logits:\n",
        "          ctbert_outputs_prob.append(logit.tolist())\n",
        "\n",
        "        total_eval_accuracy += flat_accuracy(outputs.logits, label_ids)\n",
        "        \n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    avg_val_accuracy = total_eval_accuracy / len(ctbert_validation_dataloader)\n",
        "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_val_loss = total_eval_loss / len(ctbert_validation_dataloader)\n",
        "    \n",
        "    # Measure how long the validation run took.\n",
        "    validation_time = format_time(time.time() - t0)\n",
        "    \n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "    # Record all statistics from this epoch.\n",
        "    ctbert_training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Valid. Accur.': avg_val_accuracy,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NXnJ-RoUPCnz",
        "outputId": "fb6fdfb1-d0bb-475f-dd90-dbe3019dbf42"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 5 ========\n",
            "Training...\n",
            "  Batch    40  of    214.    Elapsed: 0:00:15.\n",
            "  Batch    80  of    214.    Elapsed: 0:00:30.\n",
            "  Batch   120  of    214.    Elapsed: 0:00:45.\n",
            "  Batch   160  of    214.    Elapsed: 0:01:00.\n",
            "  Batch   200  of    214.    Elapsed: 0:01:14.\n",
            "\n",
            "  Average training loss: 0.21\n",
            "  Training epcoh took: 0:01:20\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.97\n",
            "  Validation Loss: 0.10\n",
            "  Validation took: 0:00:06\n",
            "\n",
            "======== Epoch 2 / 5 ========\n",
            "Training...\n",
            "  Batch    40  of    214.    Elapsed: 0:00:15.\n",
            "  Batch    80  of    214.    Elapsed: 0:00:30.\n",
            "  Batch   120  of    214.    Elapsed: 0:00:45.\n",
            "  Batch   160  of    214.    Elapsed: 0:00:59.\n",
            "  Batch   200  of    214.    Elapsed: 0:01:14.\n",
            "\n",
            "  Average training loss: 0.07\n",
            "  Training epcoh took: 0:01:19\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.97\n",
            "  Validation Loss: 0.08\n",
            "  Validation took: 0:00:06\n",
            "\n",
            "======== Epoch 3 / 5 ========\n",
            "Training...\n",
            "  Batch    40  of    214.    Elapsed: 0:00:15.\n",
            "  Batch    80  of    214.    Elapsed: 0:00:30.\n",
            "  Batch   120  of    214.    Elapsed: 0:00:44.\n",
            "  Batch   160  of    214.    Elapsed: 0:00:59.\n",
            "  Batch   200  of    214.    Elapsed: 0:01:14.\n",
            "\n",
            "  Average training loss: 0.02\n",
            "  Training epcoh took: 0:01:19\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.98\n",
            "  Validation Loss: 0.12\n",
            "  Validation took: 0:00:06\n",
            "\n",
            "======== Epoch 4 / 5 ========\n",
            "Training...\n",
            "  Batch    40  of    214.    Elapsed: 0:00:15.\n",
            "  Batch    80  of    214.    Elapsed: 0:00:30.\n",
            "  Batch   120  of    214.    Elapsed: 0:00:44.\n",
            "  Batch   160  of    214.    Elapsed: 0:00:59.\n",
            "  Batch   200  of    214.    Elapsed: 0:01:14.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Training epcoh took: 0:01:19\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.98\n",
            "  Validation Loss: 0.14\n",
            "  Validation took: 0:00:06\n",
            "\n",
            "======== Epoch 5 / 5 ========\n",
            "Training...\n",
            "  Batch    40  of    214.    Elapsed: 0:00:15.\n",
            "  Batch    80  of    214.    Elapsed: 0:00:30.\n",
            "  Batch   120  of    214.    Elapsed: 0:00:44.\n",
            "  Batch   160  of    214.    Elapsed: 0:00:59.\n",
            "  Batch   200  of    214.    Elapsed: 0:01:14.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Training epcoh took: 0:01:19\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.97\n",
            "  Validation Loss: 0.15\n",
            "  Validation took: 0:00:06\n",
            "\n",
            "Training complete!\n",
            "Total training took 0:07:07 (h:mm:ss)\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "seed_val = 100\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "bert_training_stats = []\n",
        "\n",
        "# Measure the total training time for the whole run.\n",
        "total_t0 = time.time()\n",
        "\n",
        "for epoch_i in range(0, epochs):\n",
        "    bert_outputs_prob = []\n",
        "  \n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_train_loss = 0\n",
        "    bert_model.train()\n",
        "\n",
        "    for step, batch in enumerate(bert_train_dataloader):\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "      \n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(bert_train_dataloader), elapsed))\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "        bert_model.zero_grad()        \n",
        "\n",
        "        outputs = bert_model(b_input_ids, \n",
        "                             attention_mask=b_input_mask, \n",
        "                             labels=b_labels)\n",
        "\n",
        "        # Accumulate the training loss over all of the batches so that we can\n",
        "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "        # single value; the `.item()` function just returns the Python value \n",
        "        # from the tensor.\n",
        "\n",
        "        total_train_loss += outputs.loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        outputs.loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(bert_model.parameters(), 1.0)\n",
        "\n",
        "        bert_optimizer.step()\n",
        "        bert_scheduler.step()\n",
        "\n",
        "    avg_train_loss = total_train_loss / len(bert_train_dataloader)            \n",
        "    \n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    bert_model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    total_eval_accuracy = 0\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in bert_validation_dataloader:\n",
        "        \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "        with torch.no_grad():\n",
        "       \n",
        "\n",
        "            # Forward pass, calculate logit predictions.\n",
        "            # token_type_ids is the same as the \"segment ids\", which \n",
        "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "            # Get the \"logits\" output by the roberta_model. The \"logits\" are the output\n",
        "            # values prior to applying an activation function like the softmax.\n",
        "            outputs = bert_model(b_input_ids, \n",
        "#                                    token_type_ids=None, \n",
        "                                   attention_mask=b_input_mask,\n",
        "                                   labels=b_labels)\n",
        "            \n",
        "        # Accumulate the validation loss.\n",
        "        total_eval_loss += outputs.loss.item()\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        outputs.logits = outputs.logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        # Calculate the accuracy for this batch of test sentences, and\n",
        "        # accumulate it over all batches.\n",
        "        for logit in outputs.logits:\n",
        "          bert_outputs_prob.append(logit.tolist())\n",
        "\n",
        "        total_eval_accuracy += flat_accuracy(outputs.logits, label_ids)\n",
        "        \n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    avg_val_accuracy = total_eval_accuracy / len(bert_validation_dataloader)\n",
        "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_val_loss = total_eval_loss / len(bert_validation_dataloader)\n",
        "    \n",
        "    # Measure how long the validation run took.\n",
        "    validation_time = format_time(time.time() - t0)\n",
        "    \n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "    # Record all statistics from this epoch.\n",
        "    bert_training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Valid. Accur.': avg_val_accuracy,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TVWWqVFPCPNd"
      },
      "outputs": [],
      "source": [
        "df_b_stats = pd.DataFrame(data=bert_training_stats)\n",
        "df_b_stats = df_b_stats.set_index('epoch')\n",
        "df_b_stats.to_csv('df_b_stats.csv')  \n",
        "np_bert_outputs_prob = np.array([np.array(xi) for xi in bert_outputs_prob])\n",
        "np.save('bert_outputs_prob.npy',np_bert_outputs_prob)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qhxltjEYO4nd",
        "outputId": "b6c8f7ac-d753-415a-a6b8-b6e29e3a5bb3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 5 ========\n",
            "Training...\n",
            "  Batch    40  of    214.    Elapsed: 0:00:17.\n",
            "  Batch    80  of    214.    Elapsed: 0:00:35.\n",
            "  Batch   120  of    214.    Elapsed: 0:00:52.\n",
            "  Batch   160  of    214.    Elapsed: 0:01:09.\n",
            "  Batch   200  of    214.    Elapsed: 0:01:24.\n",
            "\n",
            "  Average training loss: 0.24\n",
            "  Training epcoh took: 0:01:30\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.97\n",
            "  Validation Loss: 0.08\n",
            "  Validation took: 0:00:06\n",
            "\n",
            "======== Epoch 2 / 5 ========\n",
            "Training...\n",
            "  Batch    40  of    214.    Elapsed: 0:00:15.\n",
            "  Batch    80  of    214.    Elapsed: 0:00:30.\n",
            "  Batch   120  of    214.    Elapsed: 0:00:45.\n",
            "  Batch   160  of    214.    Elapsed: 0:01:00.\n",
            "  Batch   200  of    214.    Elapsed: 0:01:14.\n",
            "\n",
            "  Average training loss: 0.11\n",
            "  Training epcoh took: 0:01:20\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.98\n",
            "  Validation Loss: 0.07\n",
            "  Validation took: 0:00:06\n",
            "\n",
            "======== Epoch 3 / 5 ========\n",
            "Training...\n",
            "  Batch    40  of    214.    Elapsed: 0:00:15.\n",
            "  Batch    80  of    214.    Elapsed: 0:00:30.\n",
            "  Batch   120  of    214.    Elapsed: 0:00:44.\n",
            "  Batch   160  of    214.    Elapsed: 0:00:59.\n",
            "  Batch   200  of    214.    Elapsed: 0:01:14.\n",
            "\n",
            "  Average training loss: 0.05\n",
            "  Training epcoh took: 0:01:19\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.98\n",
            "  Validation Loss: 0.10\n",
            "  Validation took: 0:00:06\n",
            "\n",
            "======== Epoch 4 / 5 ========\n",
            "Training...\n",
            "  Batch    40  of    214.    Elapsed: 0:00:15.\n",
            "  Batch    80  of    214.    Elapsed: 0:00:30.\n",
            "  Batch   120  of    214.    Elapsed: 0:00:44.\n",
            "  Batch   160  of    214.    Elapsed: 0:00:59.\n",
            "  Batch   200  of    214.    Elapsed: 0:01:14.\n",
            "\n",
            "  Average training loss: 0.02\n",
            "  Training epcoh took: 0:01:19\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.98\n",
            "  Validation Loss: 0.11\n",
            "  Validation took: 0:00:06\n",
            "\n",
            "======== Epoch 5 / 5 ========\n",
            "Training...\n",
            "  Batch    40  of    214.    Elapsed: 0:00:15.\n",
            "  Batch    80  of    214.    Elapsed: 0:00:30.\n",
            "  Batch   120  of    214.    Elapsed: 0:00:44.\n",
            "  Batch   160  of    214.    Elapsed: 0:00:59.\n",
            "  Batch   200  of    214.    Elapsed: 0:01:14.\n",
            "\n",
            "  Average training loss: 0.01\n",
            "  Training epcoh took: 0:01:19\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.98\n",
            "  Validation Loss: 0.12\n",
            "  Validation took: 0:00:06\n",
            "\n",
            "Training complete!\n",
            "Total training took 0:07:18 (h:mm:ss)\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "\n",
        "# This training code is based on the `run_glue.py` script here:\n",
        "# a\n",
        "\n",
        "# Set the seed value all over the place to make this reproducible.\n",
        "seed_val = 100\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# We'll store a number of quantities such as training and validation loss, \n",
        "# validation accuracy, and timings.\n",
        "roberta_training_stats = []\n",
        "\n",
        "# Measure the total training time for the whole run.\n",
        "total_t0 = time.time()\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "    roberta_outputs_prob = []\n",
        "    \n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    \n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_train_loss = 0\n",
        "\n",
        "    # Put the roberta_model into training mode. Don't be mislead--the call to \n",
        "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
        "    # `dropout` and `batchnorm` layers behave differently during training\n",
        "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-roberta_model-train-do-in-pytorch)\n",
        "    roberta_model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(roberta_train_dataloader):\n",
        "\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(roberta_train_dataloader), elapsed))\n",
        "\n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
        "        # `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "\n",
        "        # Always clear any previously calculated gradients before performing a\n",
        "        # backward pass. PyTorch doesn't do this automatically because \n",
        "        # accumulating the gradients is \"convenient while training RNNs\". \n",
        "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "        roberta_model.zero_grad()        \n",
        "\n",
        "        # Perform a forward pass (evaluate the roberta_model on this training batch).\n",
        "        # The documentation for this `roberta_model` function is here: \n",
        "        # https://huggingface.co/transformers/v2.2.0/roberta_model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "        # It returns different numbers of parameters depending on what arguments\n",
        "        # are given and what flags are set. For our usage here, it returns\n",
        "        # the loss (because we provided labels) and the \"logits\"--the roberta_model\n",
        "        # outputs prior to activation.\n",
        "\n",
        "\n",
        "        outputs = roberta_model(b_input_ids, \n",
        "                            #  token_type_ids=None, \n",
        "                             attention_mask=b_input_mask, \n",
        "                             labels=b_labels)\n",
        "\n",
        "        # Accumulate the training loss over all of the batches so that we can\n",
        "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "        # single value; the `.item()` function just returns the Python value \n",
        "        # from the tensor.\n",
        "\n",
        "        total_train_loss += outputs.loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        outputs.loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(roberta_model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient.\n",
        "        # The roberta_optimizer dictates the \"update rule\"--how the parameters are\n",
        "        # modified based on their gradients, the learning rate, etc.\n",
        "        roberta_optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        roberta_scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_train_loss = total_train_loss / len(roberta_train_dataloader)            \n",
        "    \n",
        "    # Measure how long this epoch took.\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put the roberta_model in evaluation mode--the dropout layers behave differently\n",
        "    # during evaluation.\n",
        "    roberta_model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    total_eval_accuracy = 0\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in roberta_validation_dataloader:\n",
        "        \n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
        "        # the `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "        \n",
        "        # Tell pytorch not to bother with constructing the compute graph during\n",
        "        # the forward pass, since this is only needed for backprop (training).\n",
        "        with torch.no_grad():\n",
        "       \n",
        "\n",
        "            # Forward pass, calculate logit predictions.\n",
        "            # token_type_ids is the same as the \"segment ids\", which \n",
        "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "            # Get the \"logits\" output by the roberta_model. The \"logits\" are the output\n",
        "            # values prior to applying an activation function like the softmax.\n",
        "            outputs = roberta_model(b_input_ids, \n",
        "#                                    token_type_ids=None, \n",
        "                                   attention_mask=b_input_mask,\n",
        "                                   labels=b_labels)\n",
        "        # Accumulate the validation loss.\n",
        "        total_eval_loss += outputs.loss.item()\n",
        "\n",
        "        for logit in outputs.logits:\n",
        "          roberta_outputs_prob.append(logit.tolist())\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        outputs.logits = outputs.logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        # Calculate the accuracy for this batch of test sentences, and\n",
        "        # accumulate it over all batches.\n",
        "        total_eval_accuracy += flat_accuracy(outputs.logits, label_ids)\n",
        "        \n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    avg_val_accuracy = total_eval_accuracy / len(roberta_validation_dataloader)\n",
        "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_val_loss = total_eval_loss / len(roberta_validation_dataloader)\n",
        "    \n",
        "    # Measure how long the validation run took.\n",
        "    validation_time = format_time(time.time() - t0)\n",
        "    \n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "    # Record all statistics from this epoch.\n",
        "    roberta_training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Valid. Accur.': avg_val_accuracy,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jRhLuvk9h0wV"
      },
      "outputs": [],
      "source": [
        "df_r_stats = pd.DataFrame(data=roberta_training_stats)\n",
        "df_r_stats = df_r_stats.set_index('epoch')\n",
        "df_r_stats.to_csv('df_r_stats.csv')  \n",
        "roberta_outputs_prob = np.array([np.array(xi) for xi in roberta_outputs_prob])\n",
        "np.save('roberta_outputs_prob.npy',roberta_outputs_prob)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xm_BVkC4wJLN",
        "outputId": "3e8e287c-8796-4dd0-c906-c2c4908b9622"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 5 ========\n",
            "Training...\n",
            "  Batch    40  of    214.    Elapsed: 0:00:22.\n",
            "  Batch    80  of    214.    Elapsed: 0:00:44.\n",
            "  Batch   120  of    214.    Elapsed: 0:01:06.\n",
            "  Batch   160  of    214.    Elapsed: 0:01:27.\n",
            "  Batch   200  of    214.    Elapsed: 0:01:47.\n",
            "\n",
            "  Average training loss: 0.27\n",
            "  Training epcoh took: 0:01:54\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.96\n",
            "  Validation Loss: 0.15\n",
            "  Validation took: 0:00:09\n",
            "\n",
            "======== Epoch 2 / 5 ========\n",
            "Training...\n",
            "  Batch    40  of    214.    Elapsed: 0:00:19.\n",
            "  Batch    80  of    214.    Elapsed: 0:00:38.\n",
            "  Batch   120  of    214.    Elapsed: 0:00:57.\n",
            "  Batch   160  of    214.    Elapsed: 0:01:16.\n",
            "  Batch   200  of    214.    Elapsed: 0:01:35.\n",
            "\n",
            "  Average training loss: 0.10\n",
            "  Training epcoh took: 0:01:42\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.96\n",
            "  Validation Loss: 0.10\n",
            "  Validation took: 0:00:09\n",
            "\n",
            "======== Epoch 3 / 5 ========\n",
            "Training...\n",
            "  Batch    40  of    214.    Elapsed: 0:00:19.\n",
            "  Batch    80  of    214.    Elapsed: 0:00:38.\n",
            "  Batch   120  of    214.    Elapsed: 0:00:57.\n",
            "  Batch   160  of    214.    Elapsed: 0:01:16.\n",
            "  Batch   200  of    214.    Elapsed: 0:01:35.\n",
            "\n",
            "  Average training loss: 0.04\n",
            "  Training epcoh took: 0:01:42\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.97\n",
            "  Validation Loss: 0.13\n",
            "  Validation took: 0:00:09\n",
            "\n",
            "======== Epoch 4 / 5 ========\n",
            "Training...\n",
            "  Batch    40  of    214.    Elapsed: 0:00:19.\n",
            "  Batch    80  of    214.    Elapsed: 0:00:38.\n",
            "  Batch   120  of    214.    Elapsed: 0:00:57.\n",
            "  Batch   160  of    214.    Elapsed: 0:01:16.\n",
            "  Batch   200  of    214.    Elapsed: 0:01:35.\n",
            "\n",
            "  Average training loss: 0.02\n",
            "  Training epcoh took: 0:01:41\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.97\n",
            "  Validation Loss: 0.15\n",
            "  Validation took: 0:00:09\n",
            "\n",
            "======== Epoch 5 / 5 ========\n",
            "Training...\n",
            "  Batch    40  of    214.    Elapsed: 0:00:19.\n",
            "  Batch    80  of    214.    Elapsed: 0:00:38.\n",
            "  Batch   120  of    214.    Elapsed: 0:00:57.\n",
            "  Batch   160  of    214.    Elapsed: 0:01:16.\n",
            "  Batch   200  of    214.    Elapsed: 0:01:35.\n",
            "\n",
            "  Average training loss: 0.01\n",
            "  Training epcoh took: 0:01:41\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.97\n",
            "  Validation Loss: 0.14\n",
            "  Validation took: 0:00:09\n",
            "\n",
            "Training complete!\n",
            "Total training took 0:09:26 (h:mm:ss)\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "\n",
        "# This training code is based on the `run_glue.py` script here:\n",
        "# a\n",
        "\n",
        "# Set the seed value all over the place to make this reproducible.\n",
        "seed_val = 100\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# We'll store a number of quantities such as training and validation loss, \n",
        "# validation accuracy, and timings.\n",
        "xlnet_training_stats = []\n",
        "\n",
        "# Measure the total training time for the whole run.\n",
        "total_t0 = time.time()\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "    xlnet_outputs_prob = []\n",
        "    answers = []\n",
        "    \n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    \n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_train_loss = 0\n",
        "\n",
        "    xlnet_model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(xlnet_train_dataloader):\n",
        "\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(xlnet_train_dataloader), elapsed))\n",
        "\n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
        "        # `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "\n",
        "        # Always clear any previously calculated gradients before performing a\n",
        "        # backward pass. PyTorch doesn't do this automatically because \n",
        "        # accumulating the gradients is \"convenient while training RNNs\". \n",
        "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "        xlnet_model.zero_grad()        \n",
        "\n",
        "        # Perform a forward pass (evaluate the roberta_model on this training batch).\n",
        "        # The documentation for this `roberta_model` function is here: \n",
        "        # https://huggingface.co/transformers/v2.2.0/roberta_model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "        # It returns different numbers of parameters depending on what arguments\n",
        "        # are given and what flags are set. For our usage here, it returns\n",
        "        # the loss (because we provided labels) and the \"logits\"--the roberta_model\n",
        "        # outputs prior to activation.\n",
        "\n",
        "\n",
        "        outputs = xlnet_model(b_input_ids, \n",
        "                            #  token_type_ids=None, \n",
        "                             attention_mask=b_input_mask, \n",
        "                             labels=b_labels)\n",
        "\n",
        "        # Accumulate the training loss over all of the batches so that we can\n",
        "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "        # single value; the `.item()` function just returns the Python value \n",
        "        # from the tensor.\n",
        "\n",
        "        total_train_loss += outputs.loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        outputs.loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(xlnet_model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient.\n",
        "        # The roberta_optimizer dictates the \"update rule\"--how the parameters are\n",
        "        # modified based on their gradients, the learning rate, etc.\n",
        "        xlnet_optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        xlnet_scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_train_loss = total_train_loss / len(xlnet_train_dataloader)            \n",
        "    \n",
        "    # Measure how long this epoch took.\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put the roberta_model in evaluation mode--the dropout layers behave differently\n",
        "    # during evaluation.\n",
        "    xlnet_model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    total_eval_accuracy = 0\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in xlnet_validation_dataloader:\n",
        "        \n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
        "        # the `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "        \n",
        "        # Tell pytorch not to bother with constructing the compute graph during\n",
        "        # the forward pass, since this is only needed for backprop (training).\n",
        "        with torch.no_grad():\n",
        "       \n",
        "\n",
        "            # Forward pass, calculate logit predictions.\n",
        "            # token_type_ids is the same as the \"segment ids\", which \n",
        "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "            # Get the \"logits\" output by the roberta_model. The \"logits\" are the output\n",
        "            # values prior to applying an activation function like the softmax.\n",
        "            outputs = xlnet_model(b_input_ids, \n",
        "#                                    token_type_ids=None, \n",
        "                                   attention_mask=b_input_mask,\n",
        "                                   labels=b_labels)\n",
        "            \n",
        "        # Accumulate the validation loss.\n",
        "        total_eval_loss += outputs.loss.item()\n",
        "        answers.append(b_labels.tolist())\n",
        "\n",
        "        for logit in outputs.logits:\n",
        "          xlnet_outputs_prob.append(logit.tolist())\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        outputs.logits = outputs.logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        # Calculate the accuracy for this batch of test sentences, and\n",
        "        # accumulate it over all batches.\n",
        "        total_eval_accuracy += flat_accuracy(outputs.logits, label_ids)\n",
        "        \n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    avg_val_accuracy = total_eval_accuracy / len(xlnet_validation_dataloader)\n",
        "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_val_loss = total_eval_loss / len(xlnet_validation_dataloader)\n",
        "    \n",
        "    # Measure how long the validation run took.\n",
        "    validation_time = format_time(time.time() - t0)\n",
        "    \n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "    # Record all statistics from this epoch.\n",
        "    xlnet_training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Valid. Accur.': avg_val_accuracy,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s2BZ_b7Akbkj"
      },
      "outputs": [],
      "source": [
        "df_x_stats = pd.DataFrame(data=xlnet_training_stats)\n",
        "df_x_stats = df_x_stats.set_index('epoch')\n",
        "df_x_stats.to_csv('df_x_stats.csv')  \n",
        "xlnet_outputs_prob = np.array([np.array(xi) for xi in xlnet_outputs_prob])\n",
        "np.save('xlnet_outputs_prob.npy',xlnet_outputs_prob)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z4tVxrlkkmWA"
      },
      "outputs": [],
      "source": [
        "e_answers = []\n",
        "for i in answers:\n",
        "    for j in i:\n",
        "        e_answers.append(j)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8m54I4kekoCD"
      },
      "outputs": [],
      "source": [
        "np.save('anwers.npy',np.array(e_answers))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YBpAAJtHIxSc"
      },
      "source": [
        "## Ensemble\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ebb1kdvSi_dV"
      },
      "outputs": [],
      "source": [
        "e_answers = []\n",
        "for i in answers:\n",
        "    for j in i:\n",
        "        e_answers.append(j)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6WPCnUON2r0p"
      },
      "outputs": [],
      "source": [
        "def hard(logits):\n",
        "  return np.argmax(logits, axis=1).flatten()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "miGZHgpPKfaI"
      },
      "outputs": [],
      "source": [
        "def soft(logits):\n",
        "  m = nn.Softmax(dim=1)\n",
        "  output = m(torch.tensor(logits))\n",
        "  return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T-fRkEZaYPzn"
      },
      "outputs": [],
      "source": [
        "soft_voting = torch.add(soft(xlnet_outputs_prob),soft(bert_outputs_prob))\n",
        "soft_voting = torch.add(soft_voting, soft(roberta_outputs_prob))\n",
        "soft_voting = torch.add(soft_voting, soft(ctbert_outputs_prob))\n",
        "soft_voting = torch.add(soft_voting, soft(btbert_outputs_prob))\n",
        "soft_labels = np.argmax(soft_voting, axis=1).flatten()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BtYdqqv-3WMH"
      },
      "outputs": [],
      "source": [
        "hard_voting = hard(bert_outputs_prob) + hard(roberta_outputs_prob) + hard(xlnet_outputs_prob) + hard(ctbert_outputs_prob) + hard(btbert_outputs_prob)\n",
        "hard_labels = []\n",
        "for vote in hard_voting:\n",
        "  if vote >= 2:\n",
        "    hard_labels.append(1)\n",
        "  else:\n",
        "    hard_labels.append(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oWWXqxc7KuRD"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u7HxlvOYIz3Q"
      },
      "outputs": [],
      "source": [
        "conf_matrix_soft = confusion_matrix(y_true=soft_labels, y_pred=e_answers)\n",
        "conf_matrix_hard = confusion_matrix(y_true=hard_labels, y_pred=e_answers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bOzkOtdWjyhd"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=(5, 5))\n",
        "ax.matshow(conf_matrix_soft, cmap=plt.cm.Oranges, alpha=0.3)\n",
        "for i in range(conf_matrix_soft.shape[0]):\n",
        "    for j in range(conf_matrix_soft.shape[1]):\n",
        "        ax.text(x=j, y=i,s=conf_matrix_soft[i, j], va='center', ha='center', size='xx-large')\n",
        " \n",
        "plt.xlabel('Predictions', fontsize=18)\n",
        "plt.ylabel('Actuals', fontsize=18)\n",
        "plt.title('Confusion Matrix Soft Voting', fontsize=18)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5jsN50sE4bFR"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=(5, 5))\n",
        "ax.matshow(conf_matrix_hard, cmap=plt.cm.Oranges, alpha=0.3)\n",
        "for i in range(conf_matrix_hard.shape[0]):\n",
        "    for j in range(conf_matrix_hard.shape[1]):\n",
        "        ax.text(x=j, y=i,s=conf_matrix_hard[i, j], va='center', ha='center', size='xx-large')\n",
        " \n",
        "plt.xlabel('Predictions', fontsize=18)\n",
        "plt.ylabel('Actuals', fontsize=18)\n",
        "plt.title('Confusion Matrix Hard Voting', fontsize=18)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eOE1d74TkDBQ"
      },
      "outputs": [],
      "source": [
        "print('Accuracy for soft voting: %.3f' % accuracy_score(soft_labels, e_answers))\n",
        "print('Accuracy for hard voting: %.3f' % accuracy_score(hard_labels, e_answers))\n",
        "print('F1 Score for soft voting: %.3f' % f1_score(soft_labels, e_answers))\n",
        "print('F1 Score for hard voting: %.3f' % f1_score(hard_labels, e_answers))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XSOajriNQGUk"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Create a DataFrame from our training statistics.\n",
        "df_b_stats = pd.DataFrame(data=bert_training_stats)\n",
        "df_r_stats = pd.DataFrame(data=roberta_training_stats)\n",
        "df_x_stats = pd.DataFrame(data=xlnet_training_stats)\n",
        "df_c_stats = pd.DataFrame(data=ctbert_training_stats)\n",
        "\n",
        "# Use the 'epoch' as the row index.\n",
        "df_b_stats = df_b_stats.set_index('epoch')\n",
        "df_r_stats = df_r_stats.set_index('epoch')\n",
        "df_x_stats = df_x_stats.set_index('epoch')\n",
        "df_c_stats = df_c_stats.set_index('epoch')\n",
        "\n",
        "# A hack to force the column headers to wrap.\n",
        "#df = df.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\n",
        "\n",
        "# Display the table.\n",
        "df_b_stats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S0ek--X2Bdfj"
      },
      "outputs": [],
      "source": [
        "df_r_stats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TsjTqXjRZRv6"
      },
      "outputs": [],
      "source": [
        "df_x_stats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V16_QXQmpR-B"
      },
      "outputs": [],
      "source": [
        "df_c_stats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2umGfwslyHFX"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "All_model.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}